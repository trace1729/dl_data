[
    {
      "question": "module simple_alu (\n  input [31:0] a, b,\n  input [2:0] opcode,\n  output reg [31:0] result\n);\n  // Simplified ALU supporting ADD, SUB, AND\n  always @(*) begin\n    case (opcode)\n      3'b000: result = a + b; // ADD\n      3'b001: result = a - b; // SUB\n      3'b010: result = a & b; // AND\n      default: result = 32'b0;\n    endcase\n  end\nendmodule",
      "answer": {
        "Performance": "The adder and subtractor are separate paths. For better performance, especially if targeting high frequency, consider sharing the adder logic. Subtraction can be implemented as `a + (~b + 1)`. This might slightly increase the delay of the ADD path but reduces the overall critical path if ADD and SUB were significantly different. Pipelining the ALU (registering the output `result`) is crucial for high-speed CPU designs, breaking the combinational path.",
        "Power": "Computing both ADD and SUB results implicitly (even if only one is selected by the case statement) can cause unnecessary switching. Using a shared adder/subtractor reduces the active logic for arithmetic operations. Operand isolation (gating inputs to unused functional units based on `opcode`) can further reduce dynamic power.",
        "Area": "Sharing the adder logic for subtraction (`a + ~b + 1`) significantly reduces area compared to implementing a dedicated subtractor circuit. The area saving comes from reusing the main carry-propagate logic."
      }
    },
    {
      "question": "module pipeline_stage (\n  input clk, rst,\n  input [31:0] data_in,\n  input valid_in,\n  output reg [31:0] data_out,\n  output reg valid_out\n);\n  // Simple pipeline register stage\n  always @(posedge clk or posedge rst) begin\n    if (rst) begin\n      data_out <= 32'b0;\n      valid_out <= 1'b0;\n    end else begin\n      data_out <= data_in;\n      valid_out <= valid_in;\n    end\n  end\nendmodule",
      "answer": {
        "Performance": "This basic stage works but lacks flow control. In a real pipeline, backpressure (a `ready` signal from the next stage) is needed. Without it, this stage might overwrite data if the next stage isn't ready. Add `input ready_next` and gate the register update: `if (valid_in && ready_next) begin data_out <= data_in; valid_out <= 1'b1; end else if (ready_next) valid_out <= 1'b0;`. Also need an output `ready_in` signal.",
        "Power": "The registers `data_out` and `valid_out` toggle on every clock cycle if `valid_in` is high, even if the next stage isn't ready (`ready_next` is low). Implementing proper handshaking (`valid`/`ready`) allows clock gating the registers using the enable condition (`valid_in && ready_next`), saving power when the pipeline stalls.",
        "Area": "Adding handshake logic (`ready_in`, `ready_next` handling) adds a small amount of combinational logic (AND gates, MUXes) and potentially a register for `ready_in`, slightly increasing area but is essential for correct pipeline operation."
      }
    },
    {
      "question": "module sync_fifo (\n  input clk, rst,\n  input wr_en, rd_en,\n  input [7:0] data_in,\n  output reg [7:0] data_out,\n  output reg full, empty\n);\n  parameter DEPTH = 16;\n  parameter PTR_WIDTH = 4; // $clog2(DEPTH)\n  reg [7:0] mem [DEPTH-1:0];\n  reg [PTR_WIDTH:0] wr_ptr, rd_ptr; // Use extra bit for full/empty\n\n  always @(posedge clk or posedge rst) begin\n    if (rst) begin wr_ptr <= 0; rd_ptr <= 0; end\n    else begin\n      if (wr_en && !full) wr_ptr <= wr_ptr + 1;\n      if (rd_en && !empty) rd_ptr <= rd_ptr + 1;\n    end\n  end\n  // Memory write/read logic (simplified)\n  always @(posedge clk) begin\n    if (wr_en && !full) mem[wr_ptr[PTR_WIDTH-1:0]] <= data_in;\n    if (rd_en && !empty) data_out <= mem[rd_ptr[PTR_WIDTH-1:0]];\n  end\n  // Full/empty based on pointer comparison\n  always @(*) begin\n    empty = (wr_ptr == rd_ptr);\n    full = (wr_ptr[PTR_WIDTH] != rd_ptr[PTR_WIDTH]) && (wr_ptr[PTR_WIDTH-1:0] == rd_ptr[PTR_WIDTH-1:0]);\n  end\nendmodule",
      "answer": {
        "Performance": "The combinational full/empty logic depends on the pointers, which update synchronously. This path (pointer FF -> full/empty logic) can become critical, especially for deep FIFOs with wide pointers. Registering the `full` and `empty` signals (`always @(posedge clk)`) breaks this path, improving timing at the cost of one cycle latency on the flags.",
        "Power": "The pointer registers `wr_ptr` and `rd_ptr` update whenever `wr_en`/`rd_en` are high and the FIFO is not full/empty. The full/empty logic also re-evaluates whenever pointers change. Registering the flags reduces the combinational logic switching. Using clock enables on the pointer registers (`if (wr_en && !full) ...`) is good practice.",
        "Area": "Registering the `full` and `empty` flags adds two flip-flops, a minimal area increase. The pointer comparison logic itself is relatively small. Using a counter-based approach for full/empty might save a small amount of logic compared to pointer comparison, but pointer comparison is common."
      }
    },
    {
      "question": "module direct_mapped_cache_tag_match (\n  input clk, rst,\n  input [31:0] addr,\n  input valid_in,\n  output reg hit\n);\n  parameter TAG_WIDTH = 20;\n  parameter INDEX_WIDTH = 7;\n  parameter NUM_SETS = 1 << INDEX_WIDTH; // 128 sets\n\n  reg [TAG_WIDTH-1:0] tag_ram [NUM_SETS-1:0];\n  reg valid_bits [NUM_SETS-1:0];\n\n  wire [INDEX_WIDTH-1:0] index = addr[INDEX_WIDTH+4-1:4]; // Assuming 16B blocks\n  wire [TAG_WIDTH-1:0] tag = addr[31:32-TAG_WIDTH];\n\n  always @(posedge clk) begin\n    if (valid_in) begin\n      hit <= (tag_ram[index] == tag) && valid_bits[index];\n    end else begin\n      hit <= 1'b0;\n    end\n  end\n  // Simplified: Assume tag_ram and valid_bits are updated elsewhere\nendmodule",
      "answer": {
        "Performance": "The tag match (`tag_ram[index] == tag`) is a combinational path involving RAM read and comparison. For high-speed caches, this path is often too long for a single cycle. Pipeline the lookup: Stage 1 reads `tag_ram[index]` and `valid_bits[index]`. Stage 2 performs the comparison `(read_tag == tag) && read_valid`. This increases hit latency by one cycle but allows a much higher clock frequency.",
        "Power": "Accessing the `tag_ram` and performing the comparison consumes power on every valid lookup (`valid_in`). If pipelined, the comparison logic only switches in the second stage. Implementing way prediction (if set-associative) or pre-decoding the index can help gate unnecessary tag RAM reads in unused ways/banks, saving power.",
        "Area": "Pipelining adds registers for the read tag, read valid bit, and incoming tag, increasing area slightly. The tag RAM itself is the dominant area component. For a direct-mapped cache, the comparison logic is minimal."
      }
    },
    {
      "question": "module static_branch_predictor (\n  input clk, rst,\n  input fetch_valid,\n  input [31:0] fetch_pc,\n  input branch_instr, // Indicates current instruction is a branch\n  input branch_taken_actual, // Actual outcome from execute stage\n  output reg predict_taken\n);\n  // Static predictor: Always predicts not taken\n  always @(*) begin\n    if (branch_instr)\n      predict_taken = 1'b0; // Always predict not taken\n    else\n      predict_taken = 1'b0;\n  end\n  // No learning mechanism\nendmodule",
      "answer": {
        "Performance": "Static prediction (always taken or always not taken) has poor accuracy (~50-60%). This leads to frequent pipeline flushes on mispredictions, severely impacting performance. Implement a simple dynamic predictor, like a 1-bit saturating counter (predict last outcome) or a 2-bit counter (provides hysteresis). This requires storing prediction state per branch (e.g., in a Branch History Table indexed by PC bits).",
        "Power": "Frequent pipeline flushes due to mispredictions waste significant power, as instructions fetched after the branch are discarded and the pipeline refills. Improving prediction accuracy reduces flushes, saving power.",
        "Area": "Static prediction has minimal area (just combinational logic). A simple dynamic predictor requires a small state memory (Branch History Table - BHT). A 1K-entry BHT with 2-bit counters needs 2K bits of RAM/FFs plus indexing logic, a noticeable but often worthwhile area increase for the performance gain."
      }
    },
    {
      "question": "module simple_mmu_tlb (\n  input clk, rst,\n  input [31:0] virtual_addr,\n  input lookup_valid,\n  output reg [19:0] physical_addr_tag, // PA[31:12]\n  output reg hit\n);\n  parameter TLB_ENTRIES = 32;\n  parameter VA_TAG_WIDTH = 20; // VA[31:12]\n\n  reg [VA_TAG_WIDTH-1:0] tlb_va_tags [TLB_ENTRIES-1:0];\n  reg [19:0] tlb_pa_tags [TLB_ENTRIES-1:0];\n  reg tlb_valid [TLB_ENTRIES-1:0];\n  integer i;\n\n  // Combinational TLB lookup (fully associative)\n  always @(*) begin\n    hit = 1'b0;\n    physical_addr_tag = 20'b0;\n    if (lookup_valid) begin\n      for (i = 0; i < TLB_ENTRIES; i = i + 1) begin\n        if (tlb_valid[i] && (tlb_va_tags[i] == virtual_addr[31:12])) begin\n          hit = 1'b1;\n          physical_addr_tag = tlb_pa_tags[i];\n        end\n      end\n    end\n  end\n  // Assume TLB is filled elsewhere\nendmodule",
      "answer": {
        "Performance": "A fully associative combinational lookup using a `for` loop synthesizes to a very large and slow chain of comparators and multiplexers, especially for 32+ entries. This severely limits clock frequency. Implement the TLB using a Content-Addressable Memory (CAM) structure for parallel tag matching, or pipeline the lookup (Stage 1: Read entries, Stage 2: Compare). Set-associative TLBs are also common, reducing the number of parallel comparisons needed.",
        "Power": "Comparing the input `virtual_addr` against all `TLB_ENTRIES` tags simultaneously consumes significant dynamic power due to the large number of comparators switching. Using a CAM or set-associative structure reduces the number of active comparisons. Clock gating the lookup logic when `lookup_valid` is low also saves power.",
        "Area": "Synthesizing a large combinational fully associative lookup is extremely area-intensive. Using dedicated CAM blocks (if available on the target technology) is much more area-efficient. A set-associative design (e.g., 4-way) significantly reduces the comparator logic compared to fully associative, trading complexity for a potential increase in miss rate."
      }
    },
    {
      "question": "module vector_add_gpu_kernel (\n  input clk, rst,\n  input start,\n  input [31:0] base_addr_a, base_addr_b, base_addr_c,\n  input [9:0] vector_len, // Max 1024 elements\n  output reg done\n);\n  // Simplified: Assumes memory interface exists\n  reg [9:0] index;\n  reg [31:0] data_a, data_b, sum;\n\n  always @(posedge clk or posedge rst) begin\n    if (rst) begin done <= 0; index <= 0; end\n    else if (start && !done) begin\n      // Assume memory read takes 1 cycle, add takes 1 cycle\n      // This processes one element every 2 cycles (read, then compute)\n      // Simplified memory access:\n      data_a <= read_mem(base_addr_a + index*4);\n      data_b <= read_mem(base_addr_b + index*4);\n      sum = data_a + data_b;\n      write_mem(base_addr_c + index*4, sum);\n\n      if (index == vector_len - 1) begin\n        done <= 1'b1;\n        index <= 0;\n      end else begin\n        index <= index + 1;\n      end\n    end else if (!start) begin\n       index <= 0; // Reset index when not active\n       done <= 0;\n    end\n  end\nendmodule",
      "answer": {
        "Performance": "Processing one vector element sequentially is extremely slow for GPU workloads. GPUs achieve performance through massive parallelism (SIMD/SIMT). Implement multiple parallel processing lanes. For example, use 4 parallel adders, reading 4 elements from A and B, computing 4 sums, and writing 4 results per cycle (or over a few cycles depending on memory bandwidth). This requires wider memory interfaces and replicated ALUs.",
        "Power": "Sequential processing underutilizes hardware. Parallel processing performs more work per cycle, potentially finishing faster and allowing the unit to enter a low-power state sooner. However, running multiple lanes concurrently increases peak power consumption.",
        "Area": "Implementing N parallel processing lanes requires N times the ALU resources and wider memory interfaces/internal buses, significantly increasing area. This is the fundamental trade-off in GPU design: massive area for massive parallelism and performance."
      }
    },
    {
      "question": "module async_fifo_pointers (\n  input wr_clk, rd_clk,\n  input wr_rst, rd_rst,\n  input wr_en, rd_en,\n  output reg full, empty\n  // Simplified: Only shows pointer logic and sync\n);\n  parameter DEPTH = 16;\n  parameter PTR_WIDTH = 4;\n  reg [PTR_WIDTH:0] wr_ptr, rd_ptr; // Binary pointers\n  reg [PTR_WIDTH:0] rd_ptr_synced_to_wr_clk; // rd_ptr synced to wr_clk\n  reg [PTR_WIDTH:0] wr_ptr_synced_to_rd_clk; // wr_ptr synced to rd_clk\n\n  // Write pointer logic (wr_clk domain)\n  always @(posedge wr_clk or posedge wr_rst) begin\n    if (wr_rst) wr_ptr <= 0;\n    else if (wr_en && !full) wr_ptr <= wr_ptr + 1;\n  end\n\n  // Read pointer logic (rd_clk domain)\n  always @(posedge rd_clk or posedge rd_rst) begin\n    if (rd_rst) rd_ptr <= 0;\n    else if (rd_en && !empty) rd_ptr <= rd_ptr + 1;\n  end\n\n  // Basic 2-flop synchronizers for binary pointers\n  always @(posedge wr_clk) rd_ptr_synced_to_wr_clk <= rd_ptr; // Needs 2 stages!\n  always @(posedge rd_clk) wr_ptr_synced_to_rd_clk <= wr_ptr; // Needs 2 stages!\n\n  // Full/Empty logic using potentially metastable synchronized binary pointers\n  assign full = (wr_ptr[PTR_WIDTH] != rd_ptr_synced_to_wr_clk[PTR_WIDTH]) && \n                (wr_ptr[PTR_WIDTH-1:0] == rd_ptr_synced_to_wr_clk[PTR_WIDTH-1:0]);\n  assign empty = (wr_ptr_synced_to_rd_clk == rd_ptr);\n\nendmodule",
      "answer": {
        "Performance": "Synchronizing multi-bit binary pointers directly across clock domains using simple synchronizers is unsafe and can lead to metastability issues where the synchronized value is incorrect. Use Gray code pointers. Gray code ensures only one bit changes per increment, making synchronization reliable with standard 2-flop synchronizers. Convert pointers to Gray code before synchronization and back to binary after synchronization for comparison.",
        "Power": "Incorrect synchronization can lead to spurious full/empty signals, potentially causing unnecessary stalls or data corruption, which might indirectly increase power by extending operation time. Gray code synchronization is reliable. Ensure proper clock gating based on the synchronized full/empty flags.",
        "Area": "Implementing Gray code conversion requires extra combinational logic (XOR gates) before and after the synchronizers. This adds a small amount of area compared to direct binary synchronization, but is essential for correctness. The synchronizer flip-flops themselves are required in both cases."
      }
    },
    {
      "question": "module write_through_cache (\n  input clk, rst,\n  input cpu_wr_req,\n  input [31:0] cpu_addr,\n  input [31:0] cpu_data,\n  output reg cpu_wr_ack,\n  // Simplified memory interface\n  output reg mem_wr_req,\n  output reg [31:0] mem_addr,\n  output reg [31:0] mem_data,\n  input mem_wr_ack\n);\n  // Assume cache hit/miss logic updates cache RAM\n  reg busy;\n\n  always @(posedge clk or posedge rst) begin\n    if (rst) begin cpu_wr_ack <= 0; mem_wr_req <= 0; busy <= 0; end\n    else begin\n      cpu_wr_ack <= 0; // Default\n      mem_wr_req <= 0; // Default\n\n      if (cpu_wr_req && !busy) begin\n        // Update cache RAM (logic not shown)\n        // Initiate write-through to main memory\n        mem_wr_req <= 1'b1;\n        mem_addr <= cpu_addr;\n        mem_data <= cpu_data;\n        busy <= 1'b1;\n      end\n\n      if (busy && mem_wr_ack) begin\n        cpu_wr_ack <= 1'b1; // Acknowledge CPU only after mem write completes\n        busy <= 0;\n        mem_wr_req <= 0;\n      end\n    end\n  end\nendmodule",
      "answer": {
        "Performance": "In a simple write-through cache, the CPU stalls on every write until the data is written to main memory, which can be very slow. Implement a Write Buffer. The CPU writes data to the cache and the write buffer simultaneously. The CPU gets an immediate acknowledgment (or after 1 cycle), while the write buffer handles writing the data to main memory in the background. This decouples CPU writes from slow main memory latency.",
        "Power": "Stalling the CPU frequently wastes power. A write buffer allows the CPU to continue execution, potentially finishing tasks faster and allowing the system to enter lower power states sooner. The write buffer itself consumes power when active.",
        "Area": "A write buffer requires additional storage (registers or a small FIFO) to hold pending writes (address, data, control signals). This increases area compared to a simple write-through design, but the performance improvement is usually substantial."
      }
    },
    {
      "question": "module control_fsm_mealy (\n  input clk, rst,\n  input req,\n  input condition_met,\n  output reg grant,\n  output reg action\n);\n  parameter IDLE = 2'b00, WAIT = 2'b01, DO_ACTION = 2'b10;\n  reg [1:0] state, next_state;\n\n  always @(posedge clk or posedge rst) begin\n    if (rst) state <= IDLE;\n    else state <= next_state;\n  end\n\n  // Mealy FSM: Outputs depend on state AND inputs\n  always @(*) begin\n    // Defaults\n    next_state = state;\n    grant = 1'b0;\n    action = 1'b0;\n\n    case (state)\n      IDLE: begin\n        if (req) begin\n          grant = 1'b1; // Output depends directly on input 'req'\n          next_state = WAIT;\n        end\n      end\n      WAIT: begin\n        if (condition_met) begin\n          action = 1'b1; // Output depends directly on input 'condition_met'\n          next_state = DO_ACTION;\n        end\n      end\n      DO_ACTION: begin\n        // Action completed (simplified)\n        next_state = IDLE;\n      end\n    endcase\n  end\nendmodule",
      "answer": {
        "Performance": "Mealy FSM outputs (`grant`, `action`) can change asynchronously with input changes (`req`, `condition_met`) within a clock cycle. This can lead to timing issues if these outputs feed into other synchronous logic expecting stable inputs after the clock edge. Convert to a Moore FSM by registering the outputs. Outputs then only depend on the current state and change synchronously with the clock edge, providing cleaner timing characteristics.",
        "Power": "Combinational outputs in a Mealy FSM can glitch if inputs change near the clock edge or multiple times within a cycle, causing unnecessary switching in downstream logic. Moore FSM outputs, being registered, only change once per cycle after the clock edge, reducing potential glitch power.",
        "Area": "Converting to a Moore FSM requires adding flip-flops to register the outputs (`grant`, `action`). This increases the area slightly due to the extra registers, but often simplifies timing closure."
      }
    }
  ]